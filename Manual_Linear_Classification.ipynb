{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Classification On UCI Breast Cancer Dataset**\n",
        "\n",
        "This notebook aims to write a Linear classificatin model manually with hyperparameters. Then we test the proposed model on UCI breast cancer dataset. The procedure is as follows:\n",
        "\n",
        "1. Developing Model\n",
        "\n",
        "2. Imporing UCI Breast Cancer dataset\n",
        "\n",
        "3. Testing Model on Dataset\n",
        "\n",
        "4. Enhancing results using Hyperparameter Tunning\n",
        "\n",
        "5. Cross-validating to find best model"
      ],
      "metadata": {
        "id": "noLbnyaPFZYl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Developing Model**"
      ],
      "metadata": {
        "id": "x7I3pz_3HQ9M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1. Importing required libraries"
      ],
      "metadata": {
        "id": "pYg0DFk5HYZL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "TU6VA1L0rKeT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2. Coding Model"
      ],
      "metadata": {
        "id": "UFLRc67CHiqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a Python class called LinearClassifier\n",
        "class LinearClassifier:\n",
        "    # Define the constructor method with default hyperparameters\n",
        "    def __init__(self, learning_rate=0.1, num_iterations=100, penalty='l1', C=1.0, regularization_strength=1.0):\n",
        "        # Set the hyperparameters as instance variables\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.penalty = penalty\n",
        "        self.C = C\n",
        "        self.regularization_strength = regularization_strength\n",
        "        self.weights = None  # Placeholder for the model weights\n",
        "        self.bias = None  # Placeholder for the bias term\n",
        "\n",
        "    # Method to set the hyperparameters of the model\n",
        "    def set_params(self, **params):\n",
        "        for key, value in params.items():\n",
        "            setattr(self, key, value)\n",
        "        return self\n",
        "\n",
        "    # Method to train the model on a dataset X and labels y\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape  # Get the number of samples and features in the input dataset\n",
        "        self.weights = np.zeros(n_features)  # Initialize the model weights to zero\n",
        "        self.bias = 0  # Initialize the bias term to zero\n",
        "\n",
        "        # Loop through the specified number of iterations\n",
        "        for i in range(self.num_iterations):\n",
        "            y_pred = self.sigmoid(np.dot(X, self.weights) + self.bias)  # Compute the predicted labels using the current weights and bias\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))  # Compute the derivative of the loss function with respect to the weights\n",
        "\n",
        "            # Apply L2 regularization if specified\n",
        "            if self.penalty == 'l2':\n",
        "                dw += (1 / n_samples) * self.C * self.regularization_strength * self.weights\n",
        "            # Apply L1 regularization if specified\n",
        "            elif self.penalty == 'l1':\n",
        "                dw += (1 / n_samples) * self.C * self.regularization_strength * np.sign(self.weights)\n",
        "\n",
        "            db = (1 / n_samples) * np.sum(y_pred - y)  # Compute the derivative of the loss function with respect to the bias\n",
        "\n",
        "            # Update the weights and bias using gradient descent\n",
        "            self.weights -= self.learning_rate * dw\n",
        "            self.bias -= self.learning_rate * db\n",
        "\n",
        "        return self  # Return the trained model\n",
        "\n",
        "    # Method to predict the labels of a new dataset X using the trained weights and bias\n",
        "    def predict(self, X):\n",
        "        y_pred = self.sigmoid(np.dot(X, self.weights) + self.bias)  # Compute the predicted labels using the trained weights and bias\n",
        "        return np.round(y_pred)  # Round the predicted labels to the nearest integer (0 or 1)\n",
        "\n",
        "    # Method to compute the sigmoid function\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))  # Compute the sigmoid function\n",
        "\n",
        "    # Method to compute the accuracy of the model on a dataset X and labels y\n",
        "    def score(self, X, y):\n",
        "        y_pred = self.predict(X)  # Predict the labels of the input dataset\n",
        "        return accuracy_score(y, y_pred)  # Compute the accuracy of the predicted labels\n",
        "\n",
        "    # Method to return the current hyperparameters of the model as a dictionary\n",
        "    def get_params(self, deep=True):\n",
        "        return {\n",
        "            \"learning_rate\": self.learning_rate,\n",
        "            \"num_iterations\": self.num_iterations,\n",
        "            \"penalty\": self.penalty,\n",
        "            \"C\": self.C,\n",
        "            \"regularization_strength\": self.regularization_strength\n",
        " }  # return the values of the model's parameters"
      ],
      "metadata": {
        "id": "_kh5fL1Gjbs7"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Imporing UCI Breast Cancer dataset**\n",
        "\n",
        "This could be done in two ways. First we could download the data from its origin and import it in csv format.\n",
        "\n",
        "Or we could use the scikit-learn library dataset which has our dataset."
      ],
      "metadata": {
        "id": "-6aRRlRQqg3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target"
      ],
      "metadata": {
        "id": "bvpf4qvYtb2P"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.1. We split the data to Test and Train by 1 to 4 ratio.\n",
        "\n",
        "Also use the 42 for random state so for upcoming analyzes we the exactly same Train and Test."
      ],
      "metadata": {
        "id": "iJTOv19yrPfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "s4MeiUV_rJp7"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Turning Warnings to show it once\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "UsbMafmNpyE8"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.Testing Model on Dataset**\n",
        "\n",
        "We test the model on Dataset without any tuning."
      ],
      "metadata": {
        "id": "T4GePuzNgXOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "model = LinearClassifier()\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw7oQOtLgXaj",
        "outputId": "1b96d3ea-fe41-41d0-d6f7-e0920fda2604"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.37719298245614036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Enhancing results using Hyperparameter Tunning**\n",
        "\n",
        "In this code, we try to optimize the result by hyperparameter tuning.\n",
        "\n",
        "the cv for this example is equal to \"3\""
      ],
      "metadata": {
        "id": "AunU8AXwhD3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "# Create a LinearClassifier instance\n",
        "classifier = LinearClassifier()\n",
        "\n",
        "# Define the hyperparameter grid to search over\n",
        "param_grid = {\n",
        "    'learning_rate': np.arange(0, 0.1, 0.01),\n",
        "    'num_iterations': [200, 500, 1000,1500],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [0.1, 1.0, 10.0],\n",
        "    'regularization_strength': [0.01, 0.1, 1.0]\n",
        "}\n",
        "\n",
        "# Create a GridSearchCV instance to search over the hyperparameter grid\n",
        "grid_search = GridSearchCV(classifier, param_grid, cv=3)\n",
        "\n",
        "# Fit the GridSearchCV instance to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters and corresponding classification accuracy\n",
        "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Best classification accuracy:\", grid_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tedbn_6ohDRR",
        "outputId": "9abc8e38-6359-4812-e835-6f7b6e1206ed"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'C': 0.1, 'learning_rate': 0.01, 'num_iterations': 1500, 'penalty': 'l2', 'regularization_strength': 1.0}\n",
            "Best classification accuracy: 0.9185982339955849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Cross-validating to find best model**\n",
        "\n",
        "Here we use the Hyperparameter Tuning and cross-validating to get the best result.\n",
        "\n",
        "As previous, the params have the same range. but we change the cv value from 1 to 7, to get the best accuracy. For every cv, we have the best params and best accuracy associated with these cv and params.\n"
      ],
      "metadata": {
        "id": "Eikdr8gohvhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'learning_rate': np.arange(0, 0.1, 0.01),\n",
        "    'num_iterations': [200, 500, 1000,1500],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [0.1, 1.0, 10.0],\n",
        "    'regularization_strength': [0.01, 0.1, 1.0]\n",
        "}\n",
        "\n",
        "model = LinearClassifier()\n",
        "\n",
        "# Define a range of cv values to try\n",
        "cv_range = range(2, 8)\n",
        "\n",
        "# Create an empty list to store the mean and std of the scores for each cv value\n",
        "cv_scores_mean = []\n",
        "cv_scores_std = []\n",
        "\n",
        "# Loop over the cv_range and compute the mean and std of the scores for each cv value\n",
        "for cv in cv_range:\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=cv)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    print(\"CV:\", cv)\n",
        "    print(\"Best parameters:\", grid_search.best_params_)\n",
        "    print(\"Best accuracy:\", grid_search.best_score_)\n",
        "    cv_scores = grid_search.cv_results_['mean_test_score']\n",
        "    cv_scores_mean.append(np.mean(cv_scores))\n",
        "    cv_scores_std.append(np.std(cv_scores))\n",
        "\n",
        "# Print the cv values and corresponding mean and std of the scores\n",
        "for i in range(len(cv_range)):\n",
        "    print(\"CV = %d, mean = %f, std = %f\" % (cv_range[i], cv_scores_mean[i], cv_scores_std[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS2epvZvpW4Y",
        "outputId": "ef92f439-8adc-45ad-dc96-e80c5b6f9e62"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV: 2\n",
            "Best parameters: {'C': 0.1, 'learning_rate': 0.01, 'num_iterations': 1000, 'penalty': 'l1', 'regularization_strength': 1.0}\n",
            "Best accuracy: 0.9142514877502126\n",
            "CV: 3\n",
            "Best parameters: {'C': 0.1, 'learning_rate': 0.01, 'num_iterations': 1500, 'penalty': 'l2', 'regularization_strength': 1.0}\n",
            "Best accuracy: 0.9185982339955849\n",
            "CV: 4\n",
            "Best parameters: {'C': 0.1, 'learning_rate': 0.03, 'num_iterations': 1000, 'penalty': 'l1', 'regularization_strength': 1.0}\n",
            "Best accuracy: 0.9186849868032915\n",
            "CV: 5\n",
            "Best parameters: {'C': 0.1, 'learning_rate': 0.03, 'num_iterations': 1000, 'penalty': 'l2', 'regularization_strength': 1.0}\n",
            "Best accuracy: 0.9208791208791208\n",
            "CV: 6\n",
            "Best parameters: {'C': 0.1, 'learning_rate': 0.06, 'num_iterations': 1000, 'penalty': 'l1', 'regularization_strength': 0.01}\n",
            "Best accuracy: 0.9230701754385965\n",
            "CV: 7\n",
            "Best parameters: {'C': 0.1, 'learning_rate': 0.02, 'num_iterations': 1500, 'penalty': 'l1', 'regularization_strength': 1.0}\n",
            "Best accuracy: 0.9164835164835167\n",
            "CV = 2, mean = 0.778581, std = 0.157455\n",
            "CV = 3, mean = 0.791274, std = 0.148182\n",
            "CV = 4, mean = 0.810481, std = 0.155037\n",
            "CV = 5, mean = 0.796319, std = 0.149954\n",
            "CV = 6, mean = 0.815141, std = 0.154441\n",
            "CV = 7, mean = 0.791566, std = 0.147353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The best model has accuracy of 92.31%**"
      ],
      "metadata": {
        "id": "fn_N-LnC2jRv"
      }
    }
  ]
}