{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Classification On UCI Breast Cancer Dataset**\n",
        "\n",
        "This notebook aims to write a Linear classificatin model manually with hyperparameters. Then we test the proposed model on UCI breast cancer dataset. The procedure is as follows:\n",
        "\n",
        "1. Developing Model\n",
        "\n",
        "2. Imporing UCI Breast Cancer dataset\n",
        "\n",
        "3. Testing Model on Dataset\n",
        "\n",
        "4. Enhancing results using Hyperparameter Tunning\n",
        "\n",
        "5. Cross-validating to find best model"
      ],
      "metadata": {
        "id": "noLbnyaPFZYl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Developing Model**"
      ],
      "metadata": {
        "id": "x7I3pz_3HQ9M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1. Importing required libraries"
      ],
      "metadata": {
        "id": "pYg0DFk5HYZL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "TU6VA1L0rKeT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2. Coding Model"
      ],
      "metadata": {
        "id": "UFLRc67CHiqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a Python class called LinearClassifier\n",
        "class LinearClassifier:\n",
        "    # Define the constructor method with default hyperparameters\n",
        "    def __init__(self, learning_rate=0.1, num_iterations=100, penalty='l1', C=1.0, regularization_strength=1.0):\n",
        "        # Set the hyperparameters as instance variables\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.penalty = penalty\n",
        "        self.C = C\n",
        "        self.regularization_strength = regularization_strength\n",
        "        self.weights = None  # Placeholder for the model weights\n",
        "        self.bias = None  # Placeholder for the bias term\n",
        "\n",
        "    # Method to set the hyperparameters of the model\n",
        "    def set_params(self, **params):\n",
        "        for key, value in params.items():\n",
        "            setattr(self, key, value)\n",
        "        return self\n",
        "\n",
        "    # Method to train the model on a dataset X and labels y\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape  # Get the number of samples and features in the input dataset\n",
        "        self.weights = np.zeros(n_features)  # Initialize the model weights to zero\n",
        "        self.bias = 0  # Initialize the bias term to zero\n",
        "\n",
        "        # Loop through the specified number of iterations\n",
        "        for i in range(self.num_iterations):\n",
        "            y_pred = self.sigmoid(np.dot(X, self.weights) + self.bias)  # Compute the predicted labels using the current weights and bias\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))  # Compute the derivative of the loss function with respect to the weights\n",
        "\n",
        "            # Apply L2 regularization if specified\n",
        "            if self.penalty == 'l2':\n",
        "                dw += (1 / n_samples) * self.C * self.regularization_strength * self.weights\n",
        "            # Apply L1 regularization if specified\n",
        "            elif self.penalty == 'l1':\n",
        "                dw += (1 / n_samples) * self.C * self.regularization_strength * np.sign(self.weights)\n",
        "\n",
        "            db = (1 / n_samples) * np.sum(y_pred - y)  # Compute the derivative of the loss function with respect to the bias\n",
        "\n",
        "            # Update the weights and bias using gradient descent\n",
        "            self.weights -= self.learning_rate * dw\n",
        "            self.bias -= self.learning_rate * db\n",
        "\n",
        "        return self  # Return the trained model\n",
        "\n",
        "    # Method to predict the labels of a new dataset X using the trained weights and bias\n",
        "    def predict(self, X):\n",
        "        y_pred = self.sigmoid(np.dot(X, self.weights) + self.bias)  # Compute the predicted labels using the trained weights and bias\n",
        "        return np.round(y_pred)  # Round the predicted labels to the nearest integer (0 or 1)\n",
        "\n",
        "    # Method to compute the sigmoid function\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))  # Compute the sigmoid function\n",
        "\n",
        "    # Method to compute the accuracy of the model on a dataset X and labels y\n",
        "    def score(self, X, y):\n",
        "        y_pred = self.predict(X)  # Predict the labels of the input dataset\n",
        "        return accuracy_score(y, y_pred)  # Compute the accuracy of the predicted labels\n",
        "\n",
        "    # Method to return the current hyperparameters of the model as a dictionary\n",
        "    def get_params(self, deep=True):\n",
        "        return {\n",
        "            \"learning_rate\": self.learning_rate,\n",
        "            \"num_iterations\": self.num_iterations,\n",
        "            \"penalty\": self.penalty,\n",
        "            \"C\": self.C,\n",
        "            \"regularization_strength\": self.regularization_strength\n",
        " }  # return the values of the model's parameters"
      ],
      "metadata": {
        "id": "_kh5fL1Gjbs7"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Imporing UCI Breast Cancer dataset**\n",
        "\n",
        "This could be done in two ways. First we could download the data from its origin and import it in csv format.\n",
        "\n",
        "Or we could use the scikit-learn library dataset which has our dataset.\n",
        "\n",
        "We try the first way."
      ],
      "metadata": {
        "id": "-6aRRlRQqg3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('breast-cancer-wisconsin.data', header=None)\n",
        "data.columns=['Id number','Clump Thickness','Uniformity of Cell Size','Uniformity of Cell Shape','Marginal Adhesion','Single Epithelial Cell Size','Bare Nuclei','Bland Chromatin','Normal Nucleoli','Mitoses','Class']\n",
        "data2 = data.apply(pd.to_numeric, errors='coerce') #Convert argument to numeric type and invalid parsing is set as NaN\n",
        "data = data2.dropna() #Rewrrite previous data entry with new complete data \n",
        "\n",
        "#Patient Number is not required\n",
        "del data['Id number']\n",
        "\n",
        "# Display the shape of dataset\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tmef-Tr5pw0",
        "outputId": "0807359d-d1b8-4b63-9488-0449e9695b45"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(683, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Using lambda function to change values in the Class column\n",
        "data[\"Class\"]=1*(data[\"Class\"]>3)\n",
        "\n",
        "#Display the changed records\n",
        "data[[\"Class\"]].sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3Xb2yJr6Ww7",
        "outputId": "cd0f1641-2d0b-49a8-d1f2-01fd0b2913e4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Class    239\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop([\"Class\"],axis=1)\n",
        "y = data[\"Class\"]"
      ],
      "metadata": {
        "id": "ROKXJ8n569W8"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.1. We split the data to Test and Train by 1 to 4 ratio.\n",
        "\n",
        "Also use the 42 for random state so for upcoming analyzes we the exactly same Train and Test."
      ],
      "metadata": {
        "id": "iJTOv19yrPfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "s4MeiUV_rJp7"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Turning Warnings to show it once\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "UsbMafmNpyE8"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.Testing Model on Dataset**\n",
        "\n",
        "We test the model on Dataset without any tuning."
      ],
      "metadata": {
        "id": "T4GePuzNgXOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "model = LinearClassifier()\n",
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw7oQOtLgXaj",
        "outputId": "81827c81-ecb2-4b5b-ad4e-2ca1aae4b33c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8759124087591241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Enhancing results using Hyperparameter Tunning**\n",
        "\n",
        "In this code, we try to optimize the result by hyperparameter tuning.\n",
        "\n",
        "the cv for this example is equal to \"3\""
      ],
      "metadata": {
        "id": "AunU8AXwhD3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "# Create a LinearClassifier instance\n",
        "classifier = LinearClassifier()\n",
        "\n",
        "# Define the hyperparameter grid to search over\n",
        "param_grid = {\n",
        "    'learning_rate': np.arange(0, 0.12, 0.04),\n",
        "    'num_iterations': [200, 500],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [0.1, 1.0],\n",
        "    'regularization_strength': [0.1, 1.0]\n",
        "}\n",
        "\n",
        "# Create a GridSearchCV instance to search over the hyperparameter grid\n",
        "grid_search = GridSearchCV(classifier, param_grid, cv=3)\n",
        "\n",
        "# Fit the GridSearchCV instance to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters and corresponding classification accuracy\n",
        "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Best classification accuracy:\", grid_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tedbn_6ohDRR",
        "outputId": "ff96e225-fc51-4a42-fc51-45e5a881d7a9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'C': 1.0, 'learning_rate': 0.08, 'num_iterations': 500, 'penalty': 'l1', 'regularization_strength': 1.0}\n",
            "Best classification accuracy: 0.9560439560439561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Cross-validating to find best model**\n",
        "\n",
        "Here we use the Hyperparameter Tuning and cross-validating to get the best result.\n",
        "\n",
        "As previous, the params have the same range. but we change the cv value from 1 to 7, to get the best accuracy. For every cv, we have the best params and best accuracy associated with these cv and params.\n"
      ],
      "metadata": {
        "id": "Eikdr8gohvhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'learning_rate': np.arange(0, 0.12, 0.04),\n",
        "    'num_iterations': [200, 500],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [0.1, 1.0],\n",
        "    'regularization_strength': [0.1, 1.0]\n",
        "}\n",
        "\n",
        "\n",
        "model = LinearClassifier()\n",
        "\n",
        "# Define a range of cv values to try\n",
        "cv_range = range(2, 6)\n",
        "\n",
        "# Create an empty list to store the mean and std of the scores for each cv value\n",
        "cv_scores_mean = []\n",
        "cv_scores_std = []\n",
        "\n",
        "# Loop over the cv_range and compute the mean and std of the scores for each cv value\n",
        "for cv in cv_range:\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=cv)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    print(\"CV:\", cv)\n",
        "    print(\"Best parameters:\", grid_search.best_params_)\n",
        "    print(\"Best accuracy:\", grid_search.best_score_)\n",
        "    cv_scores = grid_search.cv_results_['mean_test_score']\n",
        "    cv_scores_mean.append(np.mean(cv_scores))\n",
        "    cv_scores_std.append(np.std(cv_scores))\n",
        "\n",
        "# Print the cv values and corresponding mean and std of the scores\n",
        "for i in range(len(cv_range)):\n",
        "    print(\"CV = %d, mean = %f, std = %f\" % (cv_range[i], cv_scores_mean[i], cv_scores_std[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS2epvZvpW4Y",
        "outputId": "b34f2086-2bd0-4ad0-e683-8392cb6bee33"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV: 2\n",
            "Best parameters: {'C': 0.1, 'learning_rate': 0.08, 'num_iterations': 500, 'penalty': 'l1', 'regularization_strength': 0.1}\n",
            "Best accuracy: 0.956043956043956\n",
            "CV: 3\n",
            "Best parameters: {'C': 1.0, 'learning_rate': 0.08, 'num_iterations': 500, 'penalty': 'l1', 'regularization_strength': 1.0}\n",
            "Best accuracy: 0.9560439560439561\n",
            "CV: 4\n",
            "Best parameters: {'C': 1.0, 'learning_rate': 0.08, 'num_iterations': 500, 'penalty': 'l1', 'regularization_strength': 1.0}\n",
            "Best accuracy: 0.9523803134392443\n",
            "CV: 5\n",
            "Best parameters: {'C': 1.0, 'learning_rate': 0.08, 'num_iterations': 500, 'penalty': 'l1', 'regularization_strength': 1.0}\n",
            "Best accuracy: 0.9523936613844871\n",
            "CV = 2, mean = 0.846993, std = 0.126630\n",
            "CV = 3, mean = 0.842338, std = 0.123395\n",
            "CV = 4, mean = 0.843243, std = 0.123895\n",
            "CV = 5, mean = 0.846270, std = 0.125960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The best model has accuracy of 95.6%**"
      ],
      "metadata": {
        "id": "fn_N-LnC2jRv"
      }
    }
  ]
}